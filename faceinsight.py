# -*- coding: utf-8 -*-
"""FaceInsight

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wfs1tQI8U9D7oyse67JkEC3wUXYmhGBX

# Step 1: Install & Import Required Libraries
"""

# Install required libraries
!pip install deepface opencv-python-headless

# Import necessary libraries
import cv2  # OpenCV for image processing
from deepface import DeepFace  # DeepFace for facial analysis
import matplotlib.pyplot as plt
from IPython.display import display
from google.colab import files
import numpy as np
from PIL import Image
import io

"""# Step 2: Load the Pre-trained Face Detection Model"""

# Load Haarcascade classifier for face detection
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

"""# Step 3: Upload an Image File"""

def upload_image():
    """
    Allows the user to upload an image file.
    """
    uploaded = files.upload()
    for filename in uploaded.keys():
        img = Image.open(io.BytesIO(uploaded[filename]))
        img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        display(img)
        return img_cv
    return None

# Upload an image
uploaded_image = upload_image()

"""# Step 4: Define a Function to Process an Image"""

def process_frame(frame):
    """
    Function to detect one face, analyze emotions, age, and gender, and display the results on the frame.
    """
    # Convert frame to grayscale for face detection
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Detect faces in the grayscale image
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(50, 50))

    if len(faces) > 0:
        # Only consider the first detected face
        (x, y, w, h) = faces[0]

        # Draw a rectangle around the detected face
        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 3)

        # Analyze face attributes using DeepFace
        analyze = DeepFace.analyze(frame[y:y+h, x:x+w], actions=['emotion', 'age', 'gender'], enforce_detection=False)

        # Extract gender information
        dominant_gender = max(analyze[0]['gender'], key=analyze[0]['gender'].get)
        gender_probability = analyze[0]['gender'][dominant_gender]
        gender_probability_formatted = "{:.2f}".format(gender_probability)

        # Increase font size for better visibility
        font_scale = 1.2
        thickness = 3
        color = (0, 0, 255)  # Red text color for better visibility

        # Display extracted attributes on the frame
        cv2.putText(frame, f'Emotion: {analyze[0]["dominant_emotion"]}', (x, y-50), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness)
        cv2.putText(frame, f'Age: {analyze[0]["age"]}', (x, y-20), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness)
        cv2.putText(frame, f'Gender: {dominant_gender} ({gender_probability_formatted}%)', (x, y+30), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness)

    return frame

"""# Step 5: Load and Process the Captured Image"""

# Process the uploaded image using the defined function
if uploaded_image is not None:
    processed_image = process_frame(uploaded_image)

    # Display the processed image
    plt.figure(figsize=(10, 8))  # Increase figure size for better display
    plt.imshow(cv2.cvtColor(processed_image, cv2.COLOR_BGR2RGB))
    plt.axis("off")
    plt.show()